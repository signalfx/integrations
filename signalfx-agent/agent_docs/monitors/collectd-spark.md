
<!--- Generated by to-integrations-repo script in Smart Agent repo, DO NOT MODIFY HERE --->
<!--- GENERATED BY gomplate from scripts/docs/templates/monitor-page.md.tmpl --->

# collectd/spark

Monitor Type: `collectd/spark` ([Source](https://github.com/signalfx/signalfx-agent/tree/master/pkg/monitors/collectd/spark))

**Accepts Endpoints**: **Yes**

**Multiple Instances Allowed**: Yes

## Overview

This integration collects metrics about a Spark cluster using the [collectd Spark Python
plugin](https://github.com/signalfx/collectd-spark). That plugin collects
metrics from Spark cluster and instances by hitting endpoints specified in
Spark's [Monitoring and Instrumentation
documentation](https://spark.apache.org/docs/latest/monitoring.html) under
`REST API` and `Metrics`.

The following cluster modes are supported only through HTTP endpoints:
- Standalone
- Mesos
- Hadoop YARN

You must specify distinct monitor configurations and discovery rules for
master and worker processes.  For the master configuration, set `isMaster`
to true.

When running Spark on Apache Hadoop / YARN, this integration is only capable
of reporting application metrics from the master node.  Use the
collectd/hadoop monitor to report on the health of the cluster.

<!--- SETUP --->
### Example config:

An example configuration for monitoring applications on YARN
```yaml
monitors:
  - type: collectd/spark
    host: 000.000.000.000
    port: 8088
    clusterType: Yarn
    isMaster: true
    collectApplicationMetrics: true
```


## Configuration

To activate this monitor in the Smart Agent, add the following to your
agent config:

```
monitors:  # All monitor config goes under this key
 - type: collectd/spark
   ...  # Additional config
```

**For a list of monitor options that are common to all monitors, see [Common
Configuration](../monitor-config.html#common-configuration).**


| Config option | Required | Type | Description |
| --- | --- | --- | --- |
| `pythonBinary` | no | `string` | Path to a python binary that should be used to execute the Python code. If not set, a built-in runtime will be used.  Can include arguments to the binary as well. |
| `host` | **yes** | `string` |  |
| `port` | **yes** | `integer` |  |
| `isMaster` | no | `bool` | Set to `true` when monitoring a master Spark node (**default:** `false`) |
| `clusterType` | **yes** | `string` | Should be one of `Standalone` or `Mesos` or `Yarn`.  Cluster metrics will not be collected on Yarn.  Please use the collectd/hadoop monitor to gain insights to your cluster's health. |
| `collectApplicationMetrics` | no | `bool` |  (**default:** `false`) |
| `enhancedMetrics` | no | `bool` |  (**default:** `false`) |


## Metrics

These are the metrics available for this monitor.
Metrics that are categorized as
[container/host](https://docs.signalfx.com/en/latest/admin-guide/usage.html#about-custom-bundled-and-high-resolution-metrics)
(*default*) are ***in bold and italics*** in the list below.


 - `counter.HiveExternalCatalog.fileCacheHits` (*counter*)<br>    Total number of file level cache hits occurred
 - `counter.HiveExternalCatalog.filesDiscovered` (*counter*)<br>    Total number of files discovered
 - `counter.HiveExternalCatalog.hiveClientCalls` (*counter*)<br>    Total number of client calls sent to Hive for query processing
 - `counter.HiveExternalCatalog.parallelListingJobCount` (*counter*)<br>    Total number of Hive-specific jobs running in parallel
 - `counter.HiveExternalCatalog.partitionsFetched` (*counter*)<br>    Total number of partitions fetched
 - `counter.spark.driver.completed_tasks` (*counter*)<br>    Total number of completed tasks in driver mapped to a particular application
 - ***`counter.spark.driver.disk_used`*** (*counter*)<br>    Amount of disk used by driver mapped to a particular application
 - `counter.spark.driver.failed_tasks` (*counter*)<br>    Total number of failed tasks in driver mapped to a particular application
 - ***`counter.spark.driver.memory_used`*** (*counter*)<br>    Amount of memory used by driver mapped to a particular application
 - `counter.spark.driver.total_duration` (*counter*)<br>    Fraction of time spent by driver mapped to a particular application
 - ***`counter.spark.driver.total_input_bytes`*** (*counter*)<br>    Number of input bytes in driver mapped to a particular application
 - ***`counter.spark.driver.total_shuffle_read`*** (*counter*)<br>    Size read during a shuffle in driver mapped to a particular application
 - ***`counter.spark.driver.total_shuffle_write`*** (*counter*)<br>    Size written to during a shuffle in driver mapped to a particular application
 - ***`counter.spark.driver.total_tasks`*** (*counter*)<br>    Total number of tasks in driver mapped to a particular application
 - `counter.spark.executor.completed_tasks` (*counter*)<br>    Completed tasks across executors working for a particular application
 - ***`counter.spark.executor.disk_used`*** (*counter*)<br>    Amount of disk used across executors working for a particular application
 - `counter.spark.executor.failed_tasks` (*counter*)<br>    Failed tasks across executors working for a particular application
 - ***`counter.spark.executor.memory_used`*** (*counter*)<br>    Amount of memory used across executors working for a particular application
 - `counter.spark.executor.total_duration` (*counter*)<br>    Fraction of time spent across executors working for a particular application
 - ***`counter.spark.executor.total_input_bytes`*** (*counter*)<br>    Number of input bytes across executors working for a particular application
 - ***`counter.spark.executor.total_shuffle_read`*** (*counter*)<br>    Size read during a shuffle in a particular application's executors
 - ***`counter.spark.executor.total_shuffle_write`*** (*counter*)<br>    Size written to during a shuffle in a particular application's executors
 - `counter.spark.executor.total_tasks` (*counter*)<br>    Total tasks across executors working for a particular application
 - ***`counter.spark.streaming.num_processed_records`*** (*counter*)<br>    Number of processed records in a streaming application
 - ***`counter.spark.streaming.num_received_records`*** (*counter*)<br>    Number of received records in a streaming application
 - ***`counter.spark.streaming.num_total_completed_batches`*** (*counter*)<br>    Number of batches completed in a streaming application
 - `gauge.jvm.MarkSweepCompact.count` (*gauge*)<br>    Garbage collection count
 - `gauge.jvm.MarkSweepCompact.time` (*gauge*)<br>    Garbage collection time
 - ***`gauge.jvm.heap.committed`*** (*gauge*)<br>    Amount of committed heap memory (in MB)
 - ***`gauge.jvm.heap.used`*** (*gauge*)<br>    Amount of used heap memory (in MB)
 - ***`gauge.jvm.non-heap.committed`*** (*gauge*)<br>    Amount of committed non-heap memory (in MB)
 - ***`gauge.jvm.non-heap.used`*** (*gauge*)<br>    Amount of used non-heap memory (in MB)
 - `gauge.jvm.pools.Code-Cache.committed` (*gauge*)<br>    Amount of memory committed for compilation and storage of native code
 - `gauge.jvm.pools.Code-Cache.used` (*gauge*)<br>    Amount of memory used to compile and store native code
 - `gauge.jvm.pools.Compressed-Class-Space.committed` (*gauge*)<br>    Amount of memory committed for compressing a class object
 - `gauge.jvm.pools.Compressed-Class-Space.used` (*gauge*)<br>    Amount of memory used to compress a class object
 - `gauge.jvm.pools.Eden-Space.committed` (*gauge*)<br>    Amount of memory committed for the initial allocation of objects
 - `gauge.jvm.pools.Eden-Space.used` (*gauge*)<br>    Amount of memory used for the initial allocation of objects
 - `gauge.jvm.pools.Metaspace.committed` (*gauge*)<br>    Amount of memory committed for storing classes and classloaders
 - `gauge.jvm.pools.Metaspace.used` (*gauge*)<br>    Amount of memory used to store classes and classloaders
 - `gauge.jvm.pools.Survivor-Space.committed` (*gauge*)<br>    Amount of memory committed specifically for objects that have survived GC of the Eden Space
 - `gauge.jvm.pools.Survivor-Space.used` (*gauge*)<br>    Amount of memory used for objects that have survived GC of the Eden Space
 - `gauge.jvm.pools.Tenured-Gen.committed` (*gauge*)<br>    Amount of memory committed to store objects that have lived in the survivor space for a given period of time
 - `gauge.jvm.pools.Tenured-Gen.used` (*gauge*)<br>    Amount of memory used for objects that have lived in the survivor space for a given period of time
 - ***`gauge.jvm.total.committed`*** (*gauge*)<br>    Amount of committed JVM memory (in MB)
 - ***`gauge.jvm.total.used`*** (*gauge*)<br>    Amount of used JVM memory (in MB)
 - ***`gauge.master.aliveWorkers`*** (*gauge*)<br>    Total functioning workers
 - ***`gauge.master.apps`*** (*gauge*)<br>    Total number of active applications in the spark cluster
 - ***`gauge.master.waitingApps`*** (*gauge*)<br>    Total number of waiting applications in the spark cluster
 - ***`gauge.master.workers`*** (*gauge*)<br>    Total number of workers in spark cluster
 - `gauge.spark.driver.active_tasks` (*gauge*)<br>    Total number of active tasks in driver mapped to a particular application
 - ***`gauge.spark.driver.max_memory`*** (*gauge*)<br>    Maximum memory used by driver mapped to a particular application
 - `gauge.spark.driver.rdd_blocks` (*gauge*)<br>    Number of RDD blocks in the driver mapped to a particular application
 - `gauge.spark.executor.active_tasks` (*gauge*)<br>    Total number of active tasks across all executors working for a particular application
 - ***`gauge.spark.executor.count`*** (*gauge*)<br>    Total number of executors performing for an active application in the spark cluster
 - ***`gauge.spark.executor.max_memory`*** (*gauge*)<br>    Max memory across all executors working for a particular application
 - `gauge.spark.executor.rdd_blocks` (*gauge*)<br>    Number of RDD blocks across all executors working for a particular application
 - ***`gauge.spark.job.num_active_stages`*** (*gauge*)<br>    Total number of active stages for an active application in the spark cluster
 - ***`gauge.spark.job.num_active_tasks`*** (*gauge*)<br>    Total number of active tasks for an active application in the spark cluster
 - ***`gauge.spark.job.num_completed_stages`*** (*gauge*)<br>    Total number of completed stages for an active application in the spark cluster
 - ***`gauge.spark.job.num_completed_tasks`*** (*gauge*)<br>    Total number of completed tasks for an active application in the spark cluster
 - ***`gauge.spark.job.num_failed_stages`*** (*gauge*)<br>    Total number of failed stages for an active application in the spark cluster
 - ***`gauge.spark.job.num_failed_tasks`*** (*gauge*)<br>    Total number of failed tasks for an active application in the spark cluster
 - ***`gauge.spark.job.num_skipped_stages`*** (*gauge*)<br>    Total number of skipped stages for an active application in the spark cluster
 - ***`gauge.spark.job.num_skipped_tasks`*** (*gauge*)<br>    Total number of skipped tasks for an active application in the spark cluster
 - ***`gauge.spark.job.num_tasks`*** (*gauge*)<br>    Total number of tasks for an active application in the spark cluster
 - ***`gauge.spark.num_active_stages`*** (*gauge*)<br>    Total number of active stages for an active application in the spark cluster
 - ***`gauge.spark.num_running_jobs`*** (*gauge*)<br>    Total number of running jobs for an active application in the spark cluster
 - ***`gauge.spark.stage.disk_bytes_spilled`*** (*gauge*)<br>    Actual size written to disk for an active application in the spark cluster
 - ***`gauge.spark.stage.executor_run_time`*** (*gauge*)<br>    Fraction of time spent by (and averaged across) executors for a particular application
 - ***`gauge.spark.stage.input_bytes`*** (*gauge*)<br>    Input size for a particular application
 - ***`gauge.spark.stage.input_records`*** (*gauge*)<br>    Input records received for a particular application
 - ***`gauge.spark.stage.memory_bytes_spilled`*** (*gauge*)<br>    Size spilled to disk from memory for an active application in the spark cluster
 - ***`gauge.spark.stage.output_bytes`*** (*gauge*)<br>    Output size for a particular application
 - ***`gauge.spark.stage.output_records`*** (*gauge*)<br>    Output records written to for a particular application
 - `gauge.spark.stage.shuffle_read_bytes` (*gauge*)<br>    Read size during shuffle phase for a particular application
 - `gauge.spark.stage.shuffle_read_records` (*gauge*)<br>    Number of records read during shuffle phase for a particular application
 - `gauge.spark.stage.shuffle_write_bytes` (*gauge*)<br>    Size written during shuffle phase for a particular application
 - `gauge.spark.stage.shuffle_write_records` (*gauge*)<br>    Number of records written to during shuffle phase for a particular application
 - ***`gauge.spark.streaming.avg_input_rate`*** (*gauge*)<br>    Average input rate of records across retained batches in a streaming application
 - ***`gauge.spark.streaming.avg_processing_time`*** (*gauge*)<br>    Average processing time in a streaming application
 - ***`gauge.spark.streaming.avg_scheduling_delay`*** (*gauge*)<br>    Average scheduling delay in a streaming application
 - ***`gauge.spark.streaming.avg_total_delay`*** (*gauge*)<br>    Average total delay in a streaming application
 - ***`gauge.spark.streaming.num_active_batches`*** (*gauge*)<br>    Number of active batches in a streaming application
 - ***`gauge.spark.streaming.num_inactive_receivers`*** (*gauge*)<br>    Number of inactive receivers in a streaming application
 - ***`gauge.worker.coresFree`*** (*gauge*)<br>    Total cores free for a particular worker process
 - ***`gauge.worker.coresUsed`*** (*gauge*)<br>    Total cores used by a particular worker process
 - ***`gauge.worker.executors`*** (*gauge*)<br>    Total number of executors for a particular worker process
 - ***`gauge.worker.memFree_MB`*** (*gauge*)<br>    Total memory free for a particular worker process
 - ***`gauge.worker.memUsed_MB`*** (*gauge*)<br>    Memory used by a particular worker process

### Non-default metrics (version 4.7.0+)

To emit metrics that are not _default_, you can add those metrics in the
generic monitor-level `extraMetrics` config option.  Metrics that are derived
from specific configuration options that do not appear in the above list of
metrics do not need to be added to `extraMetrics`.

To see a list of metrics that will be emitted you can run `agent-status
monitors` after configuring this monitor in a running agent instance.

## Dimensions

The following dimensions may occur on metrics emitted by this monitor.  Some
dimensions may be specific to certain metrics.

| Name | Description |
| ---  | ---         |
| `cluster` | set to value corresponding to key `cluster` in configuration file |
| `spark_process` | Either master or worker to differentiate master- and worker- specific metrics like master.apps and worker.coresFree |



